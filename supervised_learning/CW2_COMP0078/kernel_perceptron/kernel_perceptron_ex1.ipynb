{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.823</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.809</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.828</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    1    2    3      4      5      6      7      8      9  ...    247  \\\n",
       "0    6.0 -1.0 -1.0 -1.0 -1.000 -1.000 -1.000 -1.000 -0.631  0.862  ...  0.304   \n",
       "1    5.0 -1.0 -1.0 -1.0 -0.813 -0.671 -0.809 -0.887 -0.671 -0.853  ... -0.671   \n",
       "2    4.0 -1.0 -1.0 -1.0 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000  ... -1.000   \n",
       "3    7.0 -1.0 -1.0 -1.0 -1.000 -1.000 -0.273  0.684  0.960  0.450  ... -0.318   \n",
       "4    3.0 -1.0 -1.0 -1.0 -1.000 -1.000 -0.928 -0.204  0.751  0.466  ...  0.466   \n",
       "\n",
       "     248    249    250    251    252    253    254    255  256  \n",
       "0  0.823  1.000  0.482 -0.474 -0.991 -1.000 -1.000 -1.000 -1.0  \n",
       "1 -0.671 -0.033  0.761  0.762  0.126 -0.095 -0.671 -0.828 -1.0  \n",
       "2 -1.000 -1.000 -0.109  1.000 -0.179 -1.000 -1.000 -1.000 -1.0  \n",
       "3  1.000  0.536 -0.987 -1.000 -1.000 -1.000 -1.000 -1.000 -1.0  \n",
       "4  0.639  1.000  1.000  0.791  0.439 -0.199 -0.883 -1.000 -1.0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('zipcombo.csv') #(9298, 258)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[1:]].values.copy()\n",
    "y = df['label'].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to perform mapping with the polynomial kernel\n",
    "def polynomial(X_i, X_j, d):\n",
    "    '''\n",
    "    d: dimension fo the polynomial kernel\n",
    "    '''\n",
    "    K = ( X_i.dot(X_j.T) ) ** d\n",
    "    return K\n",
    "\n",
    "#a fast implementaion of the polynomial kernel\n",
    "def fast_polynomial(X_i, X_j, d):\n",
    "    '''\n",
    "    d: dimension fo the polynomial kernel\n",
    "    '''\n",
    "    K = polynomial_kernel(X_i, Y=X_j, degree=d)\n",
    "    return K \n",
    "\n",
    "#function to perform mapping with the gaussian kernel\n",
    "def gaussian(X_i, X_j, c):\n",
    "    '''\n",
    "    c: width of the gaussian kernel\n",
    "    '''\n",
    "    m, n = len(X_i), len(X_j)\n",
    "    K = np.zeros((m,n))            #initialize the mapped feature matrix\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            K[i][j] = np.exp( -c * np.linalg.norm(X_i[i]-X_j[j]) ** 2 )\n",
    "    return K\n",
    "\n",
    "#a faster implementation of the gaussian kernel\n",
    "def fast_gaussian(X_i, X_j, c):\n",
    "    '''\n",
    "    c: width of the gaussian kernel\n",
    "    '''\n",
    "    K = euclidean_distances(X_i, X_j)\n",
    "    K = np.exp( -c * K ** 2 )\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, y, seed=None):\n",
    "    if seed:                         #set a random seed for reproducable results\n",
    "        np.random.seed(seed)\n",
    "    idx = np.arange(len(X))          \n",
    "    np.random.shuffle(idx)           #shuffle the index\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "#function to perform train-test split\n",
    "def train_test_split(X, y, train_split, shuffle, seed=None):\n",
    "    '''\n",
    "    train_split: percentage of data for training\n",
    "    '''\n",
    "    if shuffle:                                     #shuffle the data if needed\n",
    "        X, y = shuffle_data(X, y, seed)\n",
    "    n_train = int(train_split*len(X))               #find the split location\n",
    "    X_train, X_test = X[:n_train], X[n_train:]      \n",
    "    y_train, y_test = y[:n_train], y[n_train:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#function to split data for k-fold cross-validation\n",
    "def KFold(X, y, k):\n",
    "    m = len(X)\n",
    "    n_split = int(m/k)         \n",
    "    X_train_fold, X_valid_fold, y_train_fold, y_valid_fold = [], [], [], []\n",
    "    for fold in range(1, k+1):\n",
    "        X_valid = X[(fold-1)*n_split:fold*n_split]\n",
    "        y_valid = y[(fold-1)*n_split:fold*n_split]\n",
    "        X_train = np.append(X[0:(fold-1)*n_split], X[fold*n_split:], axis=0)\n",
    "        y_train = np.append(y[0:(fold-1)*n_split], y[fold*n_split:], axis=0)\n",
    "        X_train_fold.append(X_train)\n",
    "        X_valid_fold.append(X_valid)\n",
    "        y_train_fold.append(y_train)\n",
    "        y_valid_fold.append(y_valid)\n",
    "    return X_train_fold, X_valid_fold, y_train_fold, y_valid_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiKernelPerceptron(object):\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test, kernel, kernel_param, epochs):\n",
    "        \n",
    "        #initialize the datasets\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        #initialize the sizes\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = len(self.y_train)  \n",
    "        self.test_size = len(self.y_test)\n",
    "        self.classes = np.unique(np.append(self.y_train, self.y_test))\n",
    "        self.n_c = len(self.classes)\n",
    "        \n",
    "        #initialize the kernel method\n",
    "        self.kernel = kernel\n",
    "        self.kernel_param = kernel_param\n",
    "        \n",
    "        #initialize the mapped data with kernelization\n",
    "        if kernel == 'p':\n",
    "            self.K = fast_polynomial(self.X_train, self.X_train, self.kernel_param)\n",
    "            self.K_test = fast_polynomial(self.X_test, self.X_train, self.kernel_param)\n",
    "        if kernel =='g':\n",
    "            self.K = fast_gaussian(self.X_train, self.X_train, self.kernel_param)\n",
    "            self.K_test = fast_gaussian(self.X_test, self.X_train, self.kernel_param)   \n",
    "        \n",
    "        #initialize the alpha matrix: n_c × m\n",
    "        self.alpha = np.zeros(shape=(self.n_c, self.batch_size))\n",
    "        \n",
    "        #intialize the confidence matrices: m × n_c\n",
    "        self.confidence = np.zeros(shape=(self.batch_size, self.n_c))\n",
    "        self.confidence_test = np.zeros(shape=(self.batch_size, self.n_c))\n",
    "        \n",
    "        #initialize the confusion matrix: n_c × n_c\n",
    "        self.confusion = np.zeros(shape=(self.n_c, self.n_c))\n",
    "        \n",
    "\n",
    "    def predict(self, i, data):\n",
    "        if data == 'train':\n",
    "            confidence = np.dot(self.alpha, self.K[i])             #compute the confidence\n",
    "            self.confidence[i,:] = confidence                      #store the results in the condifence matrix\n",
    "            y_pred = np.argmax(confidence)                         #make the final prediction\n",
    "        elif data == 'test':\n",
    "            confidence = np.dot(self.alpha, self.K_test[i])\n",
    "            self.confidence_test[i,:] = confidence\n",
    "            y_pred = np.argmax(confidence)\n",
    "        return confidence, y_pred\n",
    "        \n",
    "    \n",
    "    def train(self):\n",
    "        for _ in range(self.epochs):                    #train the algorithm over 10 epoches\n",
    "            errors = 0                                  #reset the count of mistakes to 0 at the beginning of each epoch\n",
    "            for i in range(self.batch_size):            #sequentially train the algorithm over each sample\n",
    "                confidence, y_pred = self.predict(i, 'train')      #make prediction\n",
    "                label = int(self.y_train[i])\n",
    "                if int(y_pred) != label:                           #if the prediction does not match the label\n",
    "                    errors += 1                                    #increase the count of mistakes by 1\n",
    "                    self.alpha[label, i] += 1                      #update the alpha \n",
    "                    self.alpha[y_pred, i] -= 1\n",
    "            error_rate = (errors/self.batch_size) * 100            #compute the error rate for this epoch\n",
    "        return error_rate                                          #return the training error rate on the last epoch\n",
    "    \n",
    "    \n",
    "    def test(self):\n",
    "        errors = 0\n",
    "        for i in range(self.test_size):\n",
    "            confidence, y_pred = self.predict(i, 'test') \n",
    "            label = int(self.y_test[i])\n",
    "            if int(y_pred) != label:\n",
    "                errors += 1\n",
    "                self.confusion[label, int(y_pred)] += 1       #update the copnfusion matrix \n",
    "        for i in range(self.n_c):                             #for each class\n",
    "            count = list(self.y_test).count(i)                      #count the number of class i in the test set\n",
    "            self.confusion[i] = self.confusion[i] / count     #compute the error rates\n",
    "        error_rate = (errors/self.test_size) * 100 \n",
    "        return error_rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:13<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial order:  1 , mean train error:  9.023931164291476 , mean test error:  9.631720430107526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:13<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial order:  2 , mean train error:  4.768082817961817 , mean test error:  6.908602150537634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial order:  3 , mean train error:  2.5746168324818504 , mean test error:  4.92741935483871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial order:  4 , mean train error:  1.6509814466254369 , mean test error:  4.752688172043011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial order:  5 , mean train error:  1.1118580263511697 , mean test error:  4.048387096774194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial order:  6 , mean train error:  0.8120462489916644 , mean test error:  3.7876344086021505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial order:  7 , mean train error:  0.6460069911266471 , mean test error:  3.561827956989247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#initialization\n",
    "np.random.seed(0)\n",
    "train_split = 0.8\n",
    "d_list = np.arange(1,8)\n",
    "train_error, train_std, test_error, test_std = [], [], [], []\n",
    "\n",
    "for d in d_list:               #for different dimensions of the polynomial kernel\n",
    "    single_run_train_errors, single_run_test_errors = [], []\n",
    "    for run in tqdm(range(20)):      #perform 20 runs\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_split, shuffle=True)     #randomly split the data\n",
    "        clf = MultiKernelPerceptron(X_train, y_train, X_test, y_test, kernel='p', kernel_param=d, epochs=5)\n",
    "        train_e = clf.train()                            #compute the training error on the 80% data\n",
    "        single_run_train_errors.append(train_e)\n",
    "        test_e = clf.test()                              #compute the test error on the 20% data\n",
    "        single_run_test_errors.append(test_e) \n",
    "    train_error.append(np.mean(single_run_train_errors))\n",
    "    train_std.append(np.std(single_run_train_errors))\n",
    "    test_error.append(np.mean(single_run_test_errors))\n",
    "    test_std.append(np.std(single_run_test_errors))\n",
    "    print('Polynomial order: ', d, ', mean train error: ', train_error[-1], ', mean test error: ', test_error[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────┬──────────────────────────────┬─────────────────────────────┐\n",
      "│   d │  Mean Train Error Rates (%)  │  Mean Test Error Rates (%)  │\n",
      "├─────┼──────────────────────────────┼─────────────────────────────┤\n",
      "│   1 │        9.0239±0.2944         │        9.6317±1.8428        │\n",
      "│   2 │        4.7681±0.2877         │        6.9086±1.5810        │\n",
      "│   3 │        2.5746±0.1838         │        4.9274±0.6437        │\n",
      "│   4 │        1.6510±0.1692         │        4.7527±0.7367        │\n",
      "│   5 │        1.1119±0.1261         │        4.0484±0.6295        │\n",
      "│   6 │        0.8120±0.1401         │        3.7876±0.6084        │\n",
      "│   7 │        0.6460±0.1170         │        3.5618±0.4026        │\n",
      "└─────┴──────────────────────────────┴─────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "#tabulate the results\n",
    "data = []\n",
    "for i in range(len(d_list)):\n",
    "    train_result = f\"{'{:.4f}'.format(train_error[i])}±{'{:.4f}'.format(train_std[i])}\"\n",
    "    test_result = f\"{'{:.4f}'.format(test_error[i])}±{'{:.4f}'.format(test_std[i])}\"\n",
    "    result = [int(d_list[i]), train_result, test_result]\n",
    "    data.append(result)\n",
    "print(tabulate(data, \n",
    "               headers = [\"d\", \"Mean Train Error Rates (%)\", \"Mean Test Error Rates (%)\"], \n",
    "               tablefmt = \"simple_outline\",\n",
    "               stralign = \"center\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:33<10:35, 33.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.6021505376344085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:07<10:06, 33.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  2.849462365591398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:41<09:38, 34.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.2795698924731185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:16<09:09, 34.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.118279569892473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [02:51<08:36, 34.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.494623655913978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [03:24<07:55, 33.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  6 , test error rate:  3.6021505376344085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [03:57<07:17, 33.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.494623655913978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [04:30<06:40, 33.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  2.795698924731183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [05:02<06:05, 33.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.5483870967741935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [05:35<05:30, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  6 , test error rate:  3.4408602150537635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [06:09<04:58, 33.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.978494623655914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [06:43<04:28, 33.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  4.086021505376344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [07:17<03:56, 33.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.5483870967741935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [07:52<03:23, 33.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.5483870967741935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [08:26<02:50, 34.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.870967741935484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [09:00<02:16, 34.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  4.032258064516129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [09:35<01:42, 34.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  6 , test error rate:  3.3333333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [10:08<01:07, 33.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  2.5806451612903225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [10:41<00:33, 33.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  3.3333333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [11:14<00:00, 33.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d*:  7 , test error rate:  2.6344086021505375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#initialization \n",
    "np.random.seed(1)\n",
    "train_split = 0.8\n",
    "d_stars, test_errors = [], []\n",
    "\n",
    "for run in tqdm(range(20)):          #perform 20 runs\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_split, shuffle=True)     #randomly split the data\n",
    "    d_star, best_error = 0, float('inf')            #initialize the best d and best error\n",
    "    for d in d_list:           #try different dimensions of the polynomial kernel\n",
    "        valid_errors = []      #initialize a list to store validation errors\n",
    "        X_train_frold, X_valid_fold, y_train_fold, y_valid_fold = KFold(X_train, y_train, 5)    #split the training set into 5 folds\n",
    "        for Xtrain, Xvalid, ytrain, yvalid in zip(X_train_frold, X_valid_fold, y_train_fold, y_valid_fold):\n",
    "            clf = MultiKernelPerceptron(Xtrain, ytrain, Xvalid, yvalid, kernel='p', kernel_param=d, epochs=5)\n",
    "            train_error = clf.train()               #train the classifier\n",
    "            valid_errors.append(clf.test())         #evalaute the classifier on the validation set\n",
    "        if np.mean(valid_errors) < best_error:      #if the current d value gives a lower error rate\n",
    "            best_error = np.mean(valid_errors)      #update the best error so far\n",
    "            d_star = d                              #update the best d value so far\n",
    "    #retrain the classifier on the entire training set with the best d value\n",
    "    clf = MultiKernelPerceptron(X_train, y_train, X_test, y_test, kernel='p', kernel_param=d_star, epochs=5)   \n",
    "    train_error = clf.train()\n",
    "    test_error = clf.test()\n",
    "    test_errors.append(test_error)\n",
    "    d_stars.append(d_star)\n",
    "    print('d*: ', d_star, ', test error rate: ', test_errors[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
