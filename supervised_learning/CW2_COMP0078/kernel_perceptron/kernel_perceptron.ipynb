{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9298, 257)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.823</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.809</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.828</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    1    2    3      4      5      6      7      8      9  ...    247  \\\n",
       "0    6.0 -1.0 -1.0 -1.0 -1.000 -1.000 -1.000 -1.000 -0.631  0.862  ...  0.304   \n",
       "1    5.0 -1.0 -1.0 -1.0 -0.813 -0.671 -0.809 -0.887 -0.671 -0.853  ... -0.671   \n",
       "2    4.0 -1.0 -1.0 -1.0 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000  ... -1.000   \n",
       "3    7.0 -1.0 -1.0 -1.0 -1.000 -1.000 -0.273  0.684  0.960  0.450  ... -0.318   \n",
       "4    3.0 -1.0 -1.0 -1.0 -1.000 -1.000 -0.928 -0.204  0.751  0.466  ...  0.466   \n",
       "\n",
       "     248    249    250    251    252    253    254    255  256  \n",
       "0  0.823  1.000  0.482 -0.474 -0.991 -1.000 -1.000 -1.000 -1.0  \n",
       "1 -0.671 -0.033  0.761  0.762  0.126 -0.095 -0.671 -0.828 -1.0  \n",
       "2 -1.000 -1.000 -0.109  1.000 -0.179 -1.000 -1.000 -1.000 -1.0  \n",
       "3  1.000  0.536 -0.987 -1.000 -1.000 -1.000 -1.000 -1.000 -1.0  \n",
       "4  0.639  1.000  1.000  0.791  0.439 -0.199 -0.883 -1.000 -1.0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('zipcombo.csv') #(9298, 258)\n",
    "print(df.shape)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[1:]].values.copy()\n",
    "y = df['label'].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "import os\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import random, lax\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import jax\n",
    "\n",
    "# Set memory limit for JAX\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.5'\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "\n",
    "# --- JIT-compiled polynomial kernel ---\n",
    "@jax.jit\n",
    "def polynomial_kernel_jax(X, Y, d):\n",
    "    return (jnp.dot(X, Y.T) ** d)\n",
    "\n",
    "# --- JIT-compiled Gaussian kernel ---\n",
    "@jax.jit\n",
    "def gaussian_kernel_jax(X, Y, c):\n",
    "    # Broadcasting trick to compute pairwise distances\n",
    "    # (X.shape = [Nx, D], Y.shape = [Ny, D])\n",
    "    # distances.shape = [Nx, Ny]\n",
    "    distances = jnp.sum((X[:, None, :] - Y[None, :, :]) ** 2, axis=-1)\n",
    "    return jnp.exp(-c * distances)\n",
    "\n",
    "@jax.jit\n",
    "def shuffle_data(X, y, key):\n",
    "    idx = random.permutation(key, len(X))\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "def train_test_split(X, y, train_split, key):\n",
    "    n_train = int(train_split * len(X))\n",
    "    X_shuf, y_shuf = shuffle_data(X, y, key)\n",
    "    return X_shuf[:n_train], X_shuf[n_train:], y_shuf[:n_train], y_shuf[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiKernelPerceptronJAX:\n",
    "    def __init__(self, X_train, y_train, kernel, kernel_param, epochs):\n",
    "        # Store parameters\n",
    "        self.kernel = kernel\n",
    "        self.kernel_param = kernel_param\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # Convert data to JAX arrays\n",
    "        self.X_train = jnp.asarray(X_train, dtype=jnp.float32)\n",
    "        self.y_train = jnp.asarray(y_train, dtype=jnp.int32)\n",
    "\n",
    "        # Class info\n",
    "        self.classes = jnp.unique(self.y_train)\n",
    "        self.n_classes = len(self.classes)\n",
    "        self.n_samples = len(self.y_train)\n",
    "\n",
    "        # Precompute the training kernel\n",
    "        if self.kernel == 'p':\n",
    "            self.K_train = polynomial_kernel_jax(self.X_train, self.X_train, self.kernel_param)\n",
    "        else:\n",
    "            self.K_train = gaussian_kernel_jax(self.X_train, self.X_train, self.kernel_param)\n",
    "\n",
    "        # alpha has shape [n_classes, n_samples]\n",
    "        self.alpha = jnp.zeros((self.n_classes, self.n_samples), dtype=jnp.float32)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def predict(self, X):\n",
    "        if self.kernel == 'p':\n",
    "            K = polynomial_kernel_jax(X, self.X_train, self.kernel_param)\n",
    "        else:\n",
    "            K = gaussian_kernel_jax(X, self.X_train, self.kernel_param)\n",
    "        \n",
    "        # alpha.dot(K.T) => shape [n_classes, batch_size]\n",
    "        confidence = jnp.dot(self.alpha, K.T)\n",
    "        return jnp.argmax(confidence, axis=0)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        We replace Python loops with jax.lax.fori_loop.\n",
    "        The Perceptron update is inherently sequential,\n",
    "        but we can at least JIT-compile the loop to remove Python overhead.\n",
    "        \"\"\"\n",
    "        # We define an 'update_fn' for a single sample\n",
    "        def update_fn(i, carry):\n",
    "            alpha, errors = carry\n",
    "            # confidence shape = [n_classes,]\n",
    "            confidence = jnp.dot(alpha, self.K_train[i])\n",
    "            y_pred = jnp.argmax(confidence)\n",
    "            y_true = self.y_train[i]\n",
    "\n",
    "            mismatch = (y_pred != y_true)\n",
    "            # Add 1 to alpha[y_true, i], subtract 1 from alpha[y_pred, i] if mismatch\n",
    "            alpha = alpha.at[y_true, i].add(jnp.where(mismatch, 1.0, 0.0))\n",
    "            alpha = alpha.at[y_pred, i].add(jnp.where(mismatch, -1.0, 0.0))\n",
    "\n",
    "            errors = errors + jnp.where(mismatch, 1, 0)\n",
    "            return (alpha, errors)\n",
    "\n",
    "        # A single epoch function\n",
    "        def epoch_fn(_, alpha):\n",
    "            # We'll track errors within each epoch\n",
    "            init_carry = (alpha, 0)\n",
    "            (alpha_out, errors) = lax.fori_loop(\n",
    "                0, self.n_samples, update_fn, init_carry\n",
    "            )\n",
    "            return alpha_out, errors\n",
    "\n",
    "        # We do multiple epochs\n",
    "        alpha = self.alpha\n",
    "        total_errors = 0\n",
    "        for _ in range(self.epochs):\n",
    "            alpha, errors = epoch_fn(0, alpha)\n",
    "            total_errors = errors  # final epoch's error\n",
    "\n",
    "        # Update self.alpha\n",
    "        self.alpha = alpha\n",
    "        # Compute error rate for the final epoch\n",
    "        error_rate = (total_errors / self.n_samples) * 100\n",
    "        return error_rate\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def test(self, X_test, y_test):\n",
    "        X_test = jnp.asarray(X_test, dtype=jnp.float32)\n",
    "        y_test = jnp.asarray(y_test, dtype=jnp.int32)\n",
    "        y_pred = self.predict(X_test)\n",
    "        errors = jnp.sum(y_pred != y_test)\n",
    "        error_rate = (errors / len(y_test)) * 100\n",
    "        return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved results\n",
      "Degree 1: Train Error = 7.71 ± 0.25, Test Error = 9.35 ± 1.67\n",
      "Degree 2: Train Error = 1.59 ± 0.14, Test Error = 4.47 ± 0.69\n",
      "Degree 3: Train Error = 0.67 ± 0.10, Test Error = 3.70 ± 0.43\n",
      "Degree 4: Train Error = 0.35 ± 0.08, Test Error = 3.34 ± 0.38\n",
      "Degree 5: Train Error = 0.30 ± 0.08, Test Error = 3.33 ± 0.41\n",
      "Degree 6: Train Error = 0.22 ± 0.07, Test Error = 3.16 ± 0.40\n",
      "Degree 7: Train Error = 0.18 ± 0.06, Test Error = 3.73 ± 1.53\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "train_split = 0.8\n",
    "d_list = range(1, 8)\n",
    "results_file = 'perceptron_degree_results.npy'\n",
    "\n",
    "# Check if we have saved results\n",
    "if os.path.exists(results_file):\n",
    "    saved_results = np.load(results_file, allow_pickle=True).item()\n",
    "    train_error = saved_results['train_error']\n",
    "    train_std = saved_results['train_std']\n",
    "    test_error = saved_results['test_error']\n",
    "    test_std = saved_results['test_std']\n",
    "    print(\"Loaded saved results\")\n",
    "else:\n",
    "    train_error, train_std, test_error, test_std = [], [], [], []\n",
    "    key = random.PRNGKey(0)\n",
    "\n",
    "    for d in d_list:\n",
    "        single_run_train_errors, single_run_test_errors = [], []\n",
    "        for run in tqdm(range(20)):\n",
    "            # Split data\n",
    "            key, subkey = random.split(key)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, train_split, subkey)\n",
    "            \n",
    "            # Train model\n",
    "            clf = MultiKernelPerceptronJAX(X_train, y_train, kernel='p', kernel_param=d, epochs=5)\n",
    "            train_e = clf.train()\n",
    "            test_e = clf.test(X_test, y_test)\n",
    "            \n",
    "            single_run_train_errors.append(train_e)\n",
    "            single_run_test_errors.append(test_e)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_train = jnp.mean(jnp.array(single_run_train_errors))\n",
    "        std_train = jnp.std(jnp.array(single_run_train_errors))\n",
    "        mean_test = jnp.mean(jnp.array(single_run_test_errors))\n",
    "        std_test = jnp.std(jnp.array(single_run_test_errors))\n",
    "        train_error.append(mean_train)\n",
    "        train_std.append(std_train)\n",
    "        test_error.append(mean_test)\n",
    "        test_std.append(std_test)\n",
    "        \n",
    "        print(f'Degree {d}: Mean Train Error: {mean_train:.2f}, Mean Test Error: {mean_test:.2f}')\n",
    "    \n",
    "    # Save results\n",
    "    np.save(results_file, {\n",
    "        'train_error': train_error,\n",
    "        'train_std': train_std,\n",
    "        'test_error': test_error,\n",
    "        'test_std': test_std\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "for d, tr_e, tr_s, te_e, te_s in zip(d_list, train_error, train_std, test_error, test_std):\n",
    "    print(f\"Degree {d}: Train Error = {tr_e:.2f} ± {tr_s:.2f}, Test Error = {te_e:.2f} ± {te_s:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────┬──────────────────────────────┬─────────────────────────────┐\n",
      "│   d │  Mean Train Error Rates (%)  │  Mean Test Error Rates (%)  │\n",
      "├─────┼──────────────────────────────┼─────────────────────────────┤\n",
      "│   1 │        7.7097±0.2457         │        9.3548±1.6674        │\n",
      "│   2 │        1.5878±0.1406         │        4.4677±0.6874        │\n",
      "│   3 │        0.6722±0.0988         │        3.7016±0.4322        │\n",
      "│   4 │        0.3482±0.0757         │        3.3360±0.3834        │\n",
      "│   5 │        0.3038±0.0839         │        3.3280±0.4069        │\n",
      "│   6 │        0.2245±0.0690         │        3.1586±0.4048        │\n",
      "│   7 │        0.1795±0.0617         │        3.7285±1.5295        │\n",
      "└─────┴──────────────────────────────┴─────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "#tabulate the results\n",
    "data = []\n",
    "for i in range(len(d_list)):\n",
    "    train_result = f\"{'{:.4f}'.format(train_error[i])}±{'{:.4f}'.format(train_std[i])}\"\n",
    "    test_result = f\"{'{:.4f}'.format(test_error[i])}±{'{:.4f}'.format(test_std[i])}\"\n",
    "    result = [int(d_list[i]), train_result, test_result]\n",
    "    data.append(result)\n",
    "print(tabulate(data, \n",
    "               headers = [\"d\", \"Mean Train Error Rates (%)\", \"Mean Test Error Rates (%)\"], \n",
    "               tablefmt = \"simple_outline\",\n",
    "               stralign = \"center\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed runs:\n",
      "Run 0: d*=6, train=0.24%, test=3.66%\n",
      "Run 1: d*=7, train=0.23%, test=3.23%\n",
      "Run 2: d*=7, train=0.24%, test=3.06%\n",
      "Run 3: d*=6, train=0.20%, test=3.17%\n",
      "Run 4: d*=4, train=0.47%, test=3.39%\n",
      "Run 5: d*=6, train=0.09%, test=3.06%\n",
      "Run 6: d*=6, train=0.32%, test=3.55%\n",
      "Run 7: d*=5, train=0.42%, test=3.66%\n",
      "Run 8: d*=6, train=0.11%, test=3.12%\n",
      "Run 9: d*=4, train=0.36%, test=3.44%\n",
      "Run 10: d*=6, train=0.30%, test=3.55%\n",
      "Run 11: d*=5, train=0.20%, test=3.60%\n",
      "Run 12: d*=5, train=0.19%, test=3.98%\n",
      "Run 13: d*=7, train=0.17%, test=3.23%\n",
      "Run 14: d*=5, train=0.27%, test=3.55%\n",
      "Run 15: d*=5, train=0.17%, test=2.80%\n",
      "\n",
      "Resuming from run 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs:  25%|██▌       | 1/4 [00:21<01:03, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 16: d*=5, train=0.15%, test=2.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs:  50%|█████     | 2/4 [00:40<00:40, 20.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 17: d*=6, train=0.12%, test=3.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs:  75%|███████▌  | 3/4 [01:01<00:20, 20.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 18: d*=5, train=0.16%, test=3.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs: 100%|██████████| 4/4 [01:22<00:00, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 19: d*=5, train=0.30%, test=3.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def cross_validate_single_run(X, y, train_split=0.8, k_folds=5, d_list=range(1, 8)):\n",
    "    # Get initial train/test split\n",
    "    key = random.PRNGKey(np.random.randint(0, 1000))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_split, key)\n",
    "    \n",
    "    # Convert to numpy for cross-validation\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    best_cv_error = float('inf')\n",
    "    best_d = 1\n",
    "    \n",
    "    n_samples = len(X_train)\n",
    "    fold_size = n_samples // k_folds\n",
    "    \n",
    "    for d in d_list:\n",
    "        cv_error = 0\n",
    "        for fold in range(k_folds):\n",
    "            # Clear memory before each fold\n",
    "            gc.collect()\n",
    "            jax.clear_caches()\n",
    "            \n",
    "            # Create fold indices\n",
    "            val_start = fold * fold_size\n",
    "            val_end = val_start + fold_size if fold < k_folds - 1 else n_samples\n",
    "            \n",
    "            # Split data\n",
    "            val_idx = slice(val_start, val_end)\n",
    "            train_idx = np.concatenate([np.arange(val_start), np.arange(val_end, n_samples)])\n",
    "            \n",
    "            # Train model\n",
    "            clf = MultiKernelPerceptronJAX(\n",
    "                X_train[train_idx], y_train[train_idx],\n",
    "                kernel='p', kernel_param=d, epochs=5\n",
    "            )\n",
    "            clf.train()\n",
    "            \n",
    "            # Get validation error\n",
    "            val_error = clf.test(X_train[val_idx], y_train[val_idx])\n",
    "            cv_error += val_error\n",
    "            \n",
    "            # Clean up explicitly\n",
    "            del clf\n",
    "            gc.collect()\n",
    "            jax.clear_caches()\n",
    "            \n",
    "        cv_error /= k_folds\n",
    "        if cv_error < best_cv_error:\n",
    "            best_cv_error = cv_error\n",
    "            best_d = d\n",
    "        \n",
    "        # Clear memory after testing each d\n",
    "        gc.collect()\n",
    "        jax.clear_caches()\n",
    "    \n",
    "    # Final training with best d\n",
    "    gc.collect()\n",
    "    jax.clear_caches()\n",
    "    \n",
    "    final_clf = MultiKernelPerceptronJAX(\n",
    "        X_train, y_train,\n",
    "        kernel='p', kernel_param=best_d, epochs=5\n",
    "    )\n",
    "    train_error = final_clf.train()\n",
    "    test_error = final_clf.test(X_test, y_test)\n",
    "    \n",
    "    # Clean up before returning\n",
    "    del final_clf, X_train, X_test, y_train, y_test\n",
    "    gc.collect()\n",
    "    jax.clear_caches()\n",
    "    \n",
    "    return best_d, float(train_error), float(test_error)\n",
    "\n",
    "# Run experiment with checkpointing\n",
    "n_runs = 20\n",
    "results_file = 'cross_validation_results.npy'\n",
    "\n",
    "# Load previous results if they exist\n",
    "if os.path.exists(results_file):\n",
    "    results = np.load(results_file, allow_pickle=True).item()\n",
    "    start_run = len(results['best_d'])\n",
    "    print(f\"\\nCompleted runs:\")\n",
    "    for i in range(start_run):\n",
    "        print(f\"Run {i}: d*={results['best_d'][i]}, train={results['train_error'][i]:.2f}%, test={results['test_error'][i]:.2f}%\")\n",
    "    print(f\"\\nResuming from run {start_run}\")\n",
    "else:\n",
    "    results = {\n",
    "        'best_d': [],\n",
    "        'train_error': [],\n",
    "        'test_error': []\n",
    "    }\n",
    "    start_run = 0\n",
    "\n",
    "# Process remaining runs\n",
    "for run in tqdm(range(start_run, n_runs), desc='Processing runs'):\n",
    "    try:\n",
    "        # Clear memory before each run\n",
    "        gc.collect()\n",
    "        jax.clear_caches()\n",
    "        \n",
    "        best_d, train_error, test_error = cross_validate_single_run(X, y)\n",
    "        results['best_d'].append(best_d)\n",
    "        results['train_error'].append(train_error)\n",
    "        results['test_error'].append(test_error)\n",
    "        \n",
    "        # Save progress after each run\n",
    "        np.save(results_file, results)\n",
    "        \n",
    "        # Print progress and clear memory\n",
    "        print(f\"Run {run}: d*={best_d}, train={train_error:.2f}%, test={test_error:.2f}%\")\n",
    "        gc.collect()\n",
    "        jax.clear_caches()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in run {run}: {str(e)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬──────┬────────────────────────┐\n",
      "│  Run  │  d*  │  Test Error Rates (%)  │\n",
      "├───────┼──────┼────────────────────────┤\n",
      "│   1   │  6   │         3.6559         │\n",
      "│   2   │  7   │         3.2258         │\n",
      "│   3   │  7   │         3.0645         │\n",
      "│   4   │  6   │         3.172          │\n",
      "│   5   │  4   │         3.3871         │\n",
      "│   6   │  6   │         3.0645         │\n",
      "│   7   │  6   │         3.5484         │\n",
      "│   8   │  5   │         3.6559         │\n",
      "│   9   │  6   │         3.1183         │\n",
      "│  10   │  4   │         3.4409         │\n",
      "│  11   │  6   │         3.5484         │\n",
      "│  12   │  5   │         3.6022         │\n",
      "│  13   │  5   │         3.9785         │\n",
      "│  14   │  7   │         3.2258         │\n",
      "│  15   │  5   │         3.5484         │\n",
      "│  16   │  5   │         2.7957         │\n",
      "│  17   │  5   │         2.5806         │\n",
      "│  18   │  6   │         3.871          │\n",
      "│  19   │  5   │         3.4409         │\n",
      "│  20   │  5   │         3.1183         │\n",
      "└───────┴──────┴────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Tabulate all results\n",
    "if os.path.exists('cross_validation_results.npy'):\n",
    "    results = np.load('cross_validation_results.npy', allow_pickle=True).item()\n",
    "    data = []\n",
    "    for i in range(len(results['best_d'])):\n",
    "        test_result = f\"{'{:.4f}'.format(results['test_error'][i])}\"\n",
    "        result = [int(i+1), results['best_d'][i], test_result]\n",
    "        data.append(result)\n",
    "    print(tabulate(data, \n",
    "                  headers=[\"Run\", \"d*\", \"Test Error Rates (%)\"],\n",
    "                  tablefmt=\"simple_outline\",\n",
    "                  numalign=\"center\"))\n",
    "else:\n",
    "    print(\"No results file found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
